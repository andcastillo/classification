{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A very hard classification problem\n",
    "by: _Andrés M. Castillo_\n",
    "\n",
    "*Universidad del Valle*\n",
    "\n",
    "This notebook aims to practice the most common preprocessing steps that you must carry previously to build a classification model. We found the dataset in [Kaggle](https://www.kaggle.com/sayeera/classification). It does not have any description or discussion opened at the time I have written this. \n",
    "\n",
    "This practice aims to create fancy and meaningful charts that help in the data understanding process. As you must remember, this is one of the critical steps in the data mining process.\n",
    "\n",
    "The second part of the practice is to create a classification model that predicts or explains the job satisfaction of a company's employees, based on the related information available in this dataset. \n",
    "\n",
    "To accomplish the challenge, the student must provide a very detailed and fancy description of the variables depending on its type, and some analysis for each variable against the target variable \"jobSatisfaction\". Use histograms, pie charts, scatter plots, boxplots, violins plots depending on what is more appropriate. \n",
    "<img src=\"visu.jpeg\" alt=\"visualization\" style=\"width: 600px;\"/>\n",
    "\n",
    "We start importing the needed libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar en caso de No tener instaladas las librerias\n",
    "#!conda install -c conda-forge ipywidgets -y\n",
    "#!conda install -c anaconda graphviz python-graphviz -y\n",
    "#!conda install -c conda-forge keras -y\n",
    "#!conda install -c anaconda pydot -y\n",
    "#!conda install -c anaconda seaborn -y\n",
    "\n",
    "# importando el modulo numpy\n",
    "import numpy as np\n",
    "\n",
    "# importando el modulo pandas\n",
    "import pandas as pd\n",
    "\n",
    "# importando el modulo de expresiones regulares\n",
    "import re\n",
    "\n",
    "# importando el modulo matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importando el modulo sns de seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas is a potent toolset for data manipulations. It is very convenient to start smashing data in python. The main feature provided by Pandas is the data frame structure. You use pandas during all this course. For that reason, please get familiar with the tool:  (https://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html)\n",
    "\n",
    "## Open the dataset\n",
    "\n",
    "Each time we open a dataset file, it is good to print the column names and size of the dataset. Just to be have a first glance at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/Classification.csv\")\n",
    "print(data.columns)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, it will be good to print some lines to see how the data looks like. This can be done using the data frame function ``data.head(num_lines).``\n",
    "\n",
    "**Assignment 01**\n",
    "\n",
    "Print the first 10 lines of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # Force to \"print\" all columns\n",
    "# START CODE HERE\n",
    "# Display the first 10 rows of the data\n",
    "None\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this table, you must try to determine the data type of each column. Note that by default, the columns only have 2 types: Numerical, and String. You can see the type using the ``type(variable)`` function.\n",
    "\n",
    "You can access the columns of pandas data frame using the static or the dynamic way:\n",
    "* `data.column_name`: Static form\n",
    "* `data['column_name']`: Dynamic form\n",
    "\n",
    "And you can access the elements of a list or array using the brakets notation: \n",
    "```\n",
    "foo = [7, 3, -14]\n",
    "foo[1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data.Age[0]))   # Print the type of the Age variable. \n",
    "print(type(data['Attrition'][0]))  # Print the type of the Attrition variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 2**\n",
    "\n",
    "Store in a python list([]), all the types for each column and print it\n",
    "\n",
    "**Hint**\n",
    "\n",
    "* In python you can traverse any iterable object using the \"for\" \"in\" syntax. For example to print all the elements of a given list you simply do:\n",
    "\n",
    "```\n",
    "for value in [1, 6, 3, 7]:\n",
    "    print(value)\n",
    "```\n",
    "\n",
    "* Remember that you got the column names previously\n",
    "* You can access any column in a dataframe using its name: data['A'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "types = []\n",
    "# START CODE HERE\n",
    "None\n",
    "# END CODE HERE\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "```cpp\n",
    "[<class 'numpy.int64'>, <class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'str'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'str'>, <class 'numpy.int64'>, <class 'str'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'str'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'str'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.int64'>, <class 'numpy.bool_'>]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types for Data Mining\n",
    "\n",
    "It is important to know, that the former classification for the previous data into integers and strings is not really appropiated for most of the data mining techniques.\n",
    "\n",
    "So now, you must use your previous knowledge about data types and your capacity to undestand data, in order to classify each attribute in one of the following classes:\n",
    "* categorical data, or factors\n",
    "* Ordinal data, or levels\n",
    "* ratios, or numerical data\n",
    "* intervals. Another kind of numerical data, without an absolute 0\n",
    "* text. Used for long strings containing descriptions, or any text not representing a category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group the attributes depending on its type\n",
    "\n",
    "**Assignment 03**\n",
    "\n",
    "Create three groups of attributes: real/numerical, ordinal, and categorical. In some cases, you will need to create a 4th group for all the text columns. \n",
    "\n",
    "Check: https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START CODE HERE\n",
    "numericColumns = [None]\n",
    "factorColumns = [None]\n",
    "levelColumns = [None]\n",
    "# END CODE HERE\n",
    "\n",
    "target = \"JobSatisfaction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to convert each attribute to its corresponding data type using functions defined by pandas.\n",
    "In the following cell, we will convert the data as follows: \n",
    "* Attributes contained in the `numericColumns` to pd.to_numeric. This is not really necesary in Python but is better to be as explicit as you can.\n",
    "* Attributes contained in the `factorColumns` to unordered [CategoricalDtype](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.CategoricalDtype.html) \n",
    "* Attributes contained in the `levelColumns` to ordered CategoricalDtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# Convert to numeric attributes\n",
    "# Nothing to do in python. Numeric is the dafault\n",
    "for col in numericColumns:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    \n",
    "# loop to change each column to category type\n",
    "for col in factorColumns:\n",
    "    # START CODE HERE\n",
    "    cat_type = None\n",
    "    data[col] = None\n",
    "    # END CODE HERE\n",
    "\n",
    "# Conver to levels / Ordinals\n",
    "for col in levelColumns:\n",
    "    # START CODE HERE\n",
    "    cat_type = None\n",
    "    data[col] = None\n",
    "    # END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['JobSatisfaction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print attributes 'Attrition' and 'EnvironmentSatisfaction'. Note the difference in the printing of both columns. Interpret the diference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['EnvironmentSatisfaction'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating the data frame\n",
    "\n",
    "**Assignment 04**\n",
    "1. Create a new binary attribute for JobSatisfaction. This value will be True if JobSatisfaction is higher than 2 and False in other case.\n",
    "2. Use the EmployeeNumber as the row name for the data frame. \n",
    "3. Once you did step 2, delete the attribute EmployeeNumber and EmployeeCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new attribute to try a binary class classification first. \n",
    "# It must be categorical. But booleans are actually categoricals\n",
    "\n",
    "# START CODE HERE\n",
    "# Create new attribute call class from JobSatisfaction\n",
    "data['class'] = None\n",
    "\n",
    "# Assign EmployeeNumber to the index of the corresponding column\n",
    "data.index = None\n",
    "\n",
    "# Delete the \"EmployeeCount\" and \"EmployeeNumber\" column from the dataframe\n",
    "None\n",
    "None\n",
    "\n",
    "# START CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical data is the prefered data type for most of the data mining techniques. For that reason, Pandas comes with a builtin function to resume numerical data. Use the `data.describe()` to obtain a table with an statistical resume of your numerical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that is not the only way to undestand the data. Lets see what can be done in Python, using the **matplotlib** and **pandas**. In the following cell, we will create 2 pie charts to resume the `JobSatisfaction` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declarando un objeto tipo Figura para desarrollar los subplots\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "\n",
    "data['JobSatisfaction'].value_counts().plot(kind='pie', \n",
    "                                            figsize=(12, 10),\n",
    "                                            autopct='%1.1f%%', # add in percentages\n",
    "                                            startangle=90,     # start angle 90° (Africa)\n",
    "                                            shadow=True,       # add shadow  \n",
    "                                            explode=[0, 0, 0.1, 0.1] \n",
    "                                            )\n",
    "plt.title('Job satisfaction at 4 levels. 1 is not satisfied and 4 is very satisfied at job ')\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "data['class'].value_counts().plot(kind='pie', \n",
    "                                            figsize=(12, 10),\n",
    "                                            autopct='%1.1f%%', # add in percentages\n",
    "                                            startangle=90,     # start angle 90° (Africa)\n",
    "                                            shadow=True,       # add shadow   \n",
    "                                            explode=[0, 0.1] \n",
    "                                            )\n",
    "plt.title('Job satisfaction at 2 levels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of numerical attributes. Let's use a histrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better undestand numerical data we can use histograms. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.title('Age')\n",
    "data['Age'].plot(kind='hist', rwidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 05**\n",
    "Print a histogram for each numeric column in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declarando un objeto tipo Figura para desarrollar los subplots\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "x = 1\n",
    "# Declarando las graficas de tipo Histograma Variables Númericas\n",
    "for numAtt in numericColumns:\n",
    "    ax = fig.add_subplot(6, 3, x)\n",
    "    # START CODE HERE\n",
    "    plt.title(None)   # Add the column name as title\n",
    "    None\n",
    "    x+=1\n",
    "# START CODE HERE\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of categorical and ordinal attributes. \n",
    "\n",
    "Let's use pie charts for both. Note that each chart is clock-wise sorted based on the frequency of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 60))\n",
    "x = 1\n",
    "for catAtt in factorColumns:\n",
    "    ax = fig.add_subplot(6,3,x)\n",
    "    data[catAtt].value_counts().plot(kind='pie', ax=ax, startangle=115, fontsize=12)\n",
    "    x = x + 1\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the same for ordinal attibutes. However we would like to keep the natural order of the classes in this class. Can you find a solution for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 60))\n",
    "x = 1\n",
    "for catAtt in levelColumns:\n",
    "    ax = fig.add_subplot(6,3,x)\n",
    "    data[catAtt].value_counts().plot(kind='pie', ax=ax, startangle=115, fontsize=12)\n",
    "    x = x + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now, lets use histograms. \n",
    "\n",
    "For ordinal attributes you better keep the order of the variable, but for no ordinal, \n",
    "you better order base on the value count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a single bar plot\n",
    "data['Education'].value_counts().plot(kind='bar', figsize=(5, 5), rot=90).set_title('Education')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Create bar plots for all the factorColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 100))\n",
    "x = 1\n",
    "# START CODE HERE\n",
    "# Loop over the factorColumns\n",
    "for None in None:\n",
    "    ax = fig.add_subplot(6,7,x)\n",
    "    # Add the subplot\n",
    "    None\n",
    "    # Increment x\n",
    "    x = None\n",
    "# END CODE HERE\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can create a bar plot for an ordinal variable. In this case, note the `sort=False` as parameter for value_counts. This keeps the natural order of the classes in the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a single bar plot\n",
    "data['JobInvolvement'].value_counts(sort=False).plot(kind='bar', figsize=(5, 5), rot=90).set_title('JobInvolvement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Create bar plots for all the levelColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 60))\n",
    "x = 1\n",
    "# START CODE HERE\n",
    "# Loop over the levelColumns\n",
    "for None in None:\n",
    "    ax = fig.add_subplot(6, 6, x)\n",
    "    # Add the subplot\n",
    "    None\n",
    "    # Increment x\n",
    "    x = None\n",
    "# END CODE HERE\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate if some variables has some classification power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin plots\n",
    "\n",
    "Let's use seaborn to make some fancy charts for numeric vs categorical data. Violin plots are a powerfull tool for this purpose.\n",
    "\n",
    "See: https://seaborn.pydata.org/generated/seaborn.violinplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 20))\n",
    "x = 1\n",
    "for numAtt in numericColumns:\n",
    "    ax = fig.add_subplot(5, 3 , x)\n",
    "    sns.violinplot(x = \"JobSatisfaction\", figsize=(20, 20), y = numAtt, data = data)\n",
    "    x = x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plots\n",
    "\n",
    "Sometimes, box plots allows to display more clearly the correlation between numeric and categorical attributes\n",
    "\n",
    "See: https://seaborn.pydata.org/tutorial/categorical.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(nrows = 5, ncols = 3, figsize = (30,30))\n",
    "axes = axes.flatten()\n",
    "x = 0\n",
    "for numAtt in numericColumns:\n",
    "    # ax = fig.add_subplot(6,7,x)\n",
    "    sns.boxplot(x = \"JobSatisfaction\", y = numAtt, data = data, ax=axes[x])\n",
    "    x = x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do you see something???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical vs Categorical\n",
    "\n",
    "Now lets try to determine if some of the categorical attributes has some classification power. Let's try the count plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (20,20))\n",
    "axes = axes.flatten()\n",
    "x = 0\n",
    "for catAtt in factorColumns:\n",
    "    cross = pd.crosstab(index=data[catAtt], \n",
    "                        columns=data[\"JobSatisfaction\"],\n",
    "                        normalize='index')\n",
    "    cross.plot(kind=\"bar\", \n",
    "                 stacked=True,\n",
    "                 ax=axes[x])\n",
    "\n",
    "    #sns.countplot(y = catAtt, hue=\"JobSatisfaction\", data=data, ax=axes[x]);\n",
    "    x = x + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
